<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
      <title>https://github.com/qbikez</title>
   
   <link>http://heavymetaldev.com</link>
   <description>Developer stories from the trenches.</description>
   <language>en-uk</language>
   <managingEditor> qbik</managingEditor>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
	  <title>Measuring PowerShell hashtables performance</title>
	  <link>//powershell-hashtables</link>
	  <author>qbik</author>
	  <pubDate>2017-03-03T00:00:00+01:00</pubDate>
	  <guid>//powershell-hashtables</guid>
	  <description><![CDATA[
	     <p>Usually, Powershell is used as a &quot;glue&quot; to stitch a bunch of commands and programs together. It does not need to be a performance daemon to do that (and nobody says it is). Flexibility comes with a price. 
But there are cases, where your doing seemingly trivial things, but your script just takes years to finish. </p>

<p>There is a useful cmdlet  <a href="https://technet.microsoft.com/en-us/library/ee176899.aspx"><code>Measure-Command</code></a> that measures how long a piece of code takes to run. The usage is very simple:</p>
<div class="highlight"><pre><code class="language-" data-lang="">$timespan = Measure-Command {
    # do whatever you want to measure here
}
</code></pre></div>
<p>That&#39;s nice if you know or suspect which part of code is slow. But I would like to have something that&#39;s more like instrumentation. What I want is a list of called functions with their total run times and number of calls.</p>

<p>That&#39;s why I created a little wrapper around <code>Measure-Command</code>, called <a href="https://gist.github.com/qbikez/f59aa687035f879f70729d3d5dc311ad"><code>Measure-function</code></a>, that&#39;s able to easily gather measurements of multiple functions. So now, if I have a function that I want to measure:</p>
<div class="highlight"><pre><code class="language-" data-lang="">  function Get-Something {
    # i'm doing some heavy loading here
    return $something
  }
</code></pre></div>
<p>I just wrap the body with <code>Measure-Function</code> like this:</p>
<div class="highlight"><pre><code class="language-" data-lang="">  function Get-Something {
    Measure-Function "$($MyInvocation.MyCommand.Name)" {
      # i'm doing some heavy loading here
      return $something
    }
  }
</code></pre></div>
<p><code>Measure-Function</code> takes care of aggregating measurements, and makes sure not to measure recurence invocation. To get the results, do:</p>
<div class="highlight"><pre><code class="language-" data-lang="">$global:perfcounters | format-table -AutoSize -Wrap | out-string | write-host
</code></pre></div>
<p>Now, to pinpoint bottlenecks in your code, you can follow these steps:</p>

<ol>
<li>Start with the entry point of your script and add <code>Measure-Function</code> to it and functions that it calls. </li>
<li>Run the code and see, which function takes the most time.</li>
<li>Repeat step on with the slowest functions, until you find the bottleneck.</li>
</ol>

<h1 id="powershell-hashtable-quircks">Powershell Hashtable quircks</h1>

<p>One of the things I discovered using aforementioned method was in a place I really wasn&#39;t expecting - enumerating through a hashtable. It should be blazingly fast even in Powershell! As it turns out, it can be awfully slow - if you&#39;re not careful enough.</p>

<p>Take a look at these three simple scenarios :</p>
<div class="highlight"><pre><code class="language-" data-lang=""># $h is a hastable of size 10000 
$size = 10000
$h = @{
}
for($i = 0; $i -lt $size; $i++) {
    $h += @{ "key$i" = "value$i"  }
}

measure-function "enumerating $($h.count) items by enumerator" {
    foreach ($e in $h.GetEnumerator()) {
        $k = $e.key
        $v = $e.value
    }
}

measure-function "enumerating $($h.count) items by keys" {
    foreach ($k in $h.keys) {
        $v = $h[$k]
    }
}
measure-function "enumerating $($h.count) items with property accessor" {
    foreach ($k in $h.keys) {
        $v = $h.$k
    }
}

$global:perfcounters | format-table -AutoSize -Wrap | out-string | write-host
</code></pre></div>
<p>Each loop is enumerating over a hashtable and accessing stored values. Should be a matter of milliseconds, right? Well, let&#39;s see...</p>
<div class="highlight"><pre><code class="language-" data-lang="">name                                           elapsed          count
----                                           -------          -----
enumerating 10000 items with property accessor 00:00:30.4342957     1
enumerating 10000 items by keys                00:00:00.0479557     1
enumerating 10000 items by enumerator          00:00:00.1173057     1
</code></pre></div>
<p>As it turns out, accessing hashtable keys by property accessor takes ~800 times longer! </p>

<p>At a first glance, I would think that the form <code>$h.$k</code> would be just a syntactic sugar for <code>$h[$k]</code>. But it really isn&#39;t (and can&#39;t) be that simple. <code>$k</code> may not only be a key inside hashtable - it may as well be a property, like <code>Count</code> or a method like <code>ContainsKey</code>. So underneath, powershell has to do some really time-consuming stuff, invoking reflection, dynamics, and what not - just to get you a value from hashtable.</p>

<p>The conclusion is simple: if you know you&#39;re working with a potentially big hashtable, don&#39;t go for shortcuts and use plain old <code>$h[$k]</code>. But if you&#39;re not in a tight loop - just go with what you think is more readable.</p>

<p>Reference:
* <a href="https://technet.microsoft.com/en-us/library/ee176899.aspx"><code>Measure-Command</code></a>
* There is also 
<a href="http://stackoverflow.com/questions/7523143/powershell-2-and-net-optimize-for-extremely-large-hash-tables">a discussion on powershell hashtable insert</a>. </p>

	  ]]></description>
	</item>

	<item>
	  <title>Mercurial repository conversion</title>
	  <link>//hg-repo-conversion</link>
	  <author>qbik</author>
	  <pubDate>2017-01-22T00:00:00+01:00</pubDate>
	  <guid>//hg-repo-conversion</guid>
	  <description><![CDATA[
	     <p>Have you ever needed to split a repository, or take out just a few directories, retaining their history? 
Or maybe your repo contains too many (possibly unrelated) projects? 
Or has grown so big that you can&#39;t even clone it? </p>

<p>Mercurial&#39;s <a href="https://www.mercurial-scm.org/wiki/ConvertExtension#Usage">convert extension</a> is here to help. It&#39;s a multitool that can convert from various other VCS, like git, SVN, ect, and from HG. The last one is what we need.</p>

<h1 id="why">Why</h1>

<p>The benefits of splitting large repositories are:</p>

<ul>
<li>teams can work independently and move at different speeds</li>
<li>you can give someone (an outsourcer perhaps) access to only some parts of your codebase</li>
<li>smaller repos are easier to manage</li>
<li>some CI systems (like appveyor or travis) use a single configuration file per repo - stuffing multiple projects into these files will just complicate the build and obfuscate results<br></li>
</ul>

<h1 id="powering-up-convert-with-some-scripts">Powering up <code>convert</code> with some scripts</h1>

<p><code>convert</code> is a rather low-level tool and needs a few configuration files and commandline options to work the way you want. And let&#39;s face it - you won&#39;t be right for the first time and will need to do some tweaking.</p>

<p>That&#39;s why I created a few powershell scripts and template files to help us with conversion.</p>

<h1 id="configuration">Configuration</h1>

<ol>
<li><p>Enable the <code>convert</code> extension in <a href="http://hgtip.com/tips/beginner/2009-09-30-configuring-mercurial/">mercurial.ini</a>:</p>
<div class="highlight"><pre><code class="language-" data-lang="">[extensions]
convert =
</code></pre></div></li>
<li><p>Clone or download <a href="https://gist.github.com/qbikez/e900456032833fb2baaaee87e19a8ccd">this gist</a>. I recommend creating a separate directory (and possibly version controling it) for every conversion you make  and copying these files there. </p></li>
<li><p>Create two files: <code>branchmap.txt</code> and <code>filemap.txt</code> (you may copy them from <code>branchmap.sample.txt</code> and <code>filemap.sample.txt</code>). These are the config files we will use to tell mercurial which directories to inlcude in converted repo and how to treat branches. As you will see, these files support an extended syntax (in comparison to what <code>convert</code> understands). They are then used to generate <em>real</em> branchmap/filemap files for mercurial. </p></li>
</ol>

<p>Now, we need to fill these config files.</p>

<h2 id="sample-repository">Sample repository</h2>

<p>Let&#39;s use the repo at <a href="https://bitbucket.org/heavymetaldev/convert-me">https://bitbucket.org/heavymetaldev/convert-me</a> as an example. The structure looks like this:</p>
<div class="highlight"><pre><code class="language-" data-lang="">|-- convert-me
    |-- .hgignore
    |-- top-secret.txt
    |-- sln
    |   |-- MyProject.Core
    |   |   |-- MyProject.Core.sln
    |   |-- MyProject.Desktop
    |       |-- MyProject.Desktop.sln
    |-- src
        |-- MyProject.Core.Api
        |   |-- MyProject.Core.Api.csproj
        |-- MyProject.Core.Model
        |   |-- MyProject.Core.Model.csproj
        |-- MyProject.Core.Utils
        |   |-- MyProject.Core.Utils.csproj
        |-- MyProject.Desktop.WinForms
            |-- MyProject.Desktop.WinForms.csproj
</code></pre></div>
<blockquote>
<p>This repository contains c# projets, but scripts and methods described here can be as well applied to any other mercurial repo.</p>
</blockquote>

<p>There are two solution files <code>MyProject.Core</code> and <code>MyProject.Desktop</code>. I want to move these solutions to two separate repositories (<code>repo-a</code> and <code>repo-b</code>), along with the projects they refer to). Additionally, I want to remove the toplevel file <code>top-secret.txt</code>, as it contains confidential data.</p>

<p><code>Repo A</code> should look like this:</p>
<div class="highlight"><pre><code class="language-" data-lang="">|-- Repo-A
    |-- .hgignore
    |-- sln
    |   |-- MyProject.Core
    |   |   |-- MyProject.Core.sln
    |-- src
        |-- MyProject.Core.Api
        |   |-- MyProject.Core.Api.csproj
        |-- MyProject.Core.Model
        |   |-- MyProject.Core.Model.csproj
        |-- MyProject.Core.Utils
        |   |-- MyProject.Core.Utils.csproj
</code></pre></div>
<p><code>Repo B</code> should contain remaining projects and files:</p>
<div class="highlight"><pre><code class="language-" data-lang="">|-- Repo-B
    |-- .hgignore
    |-- sln
    |   |-- MyProject.Desktop
    |       |-- MyProject.Desktop.sln
    |-- src
        |-- MyProject.Desktop.WinForms
            |-- MyProject.Desktop.WinForms.csproj
</code></pre></div>
<h2 id="filemap-on-steroids">Filemap on steroids</h2>

<p>Let&#39;s start with filemap. It defines, which files or directories should be included (or excluded) in the new repository. You may also use it to rename files. </p>

<p>The extended filemap format supports lines in the following forms:</p>
<div class="highlight"><pre><code class="language-" data-lang=""># this is th basic mercurial stuff:
include path/to/file
exclude path/to/file
rename from/file to/file

# this is extended format:
include r:regex/to/.*/include
include r:!regex/to/.*/include/if/not/match
exclude r:regex/to/.*/exclude
exclude r:!regex/to/.*/exclude/if/not/match
include sln:path/to/something.sln
</code></pre></div>
<ul>
<li><code>r:</code> indicates that this entry is a regex. <code>r:!</code> is a negated regex (i.e.: everything that does not match this pattern).</li>
<li><code>sln:</code> is specifically for C# solution files. This will parse the <code>.sln</code> file and generate include entries for every <code>csproj</code> it contains. In other words, this will include the whole solution.</li>
</ul>

<p>Let&#39;s look at our sample repo. For converting to <code>repo-a</code>, we can use the following <code>filemap.txt</code> content:</p>
<div class="highlight"><pre><code class="language-" data-lang="">include .hgignore
include r:.*/MyProject\.Core(\..*){0,1}/
exclude top-secret.txt
</code></pre></div>
<blockquote>
<p>By default, everything that&#39;s not included gets excluded, so the last line isn&#39;t really necessary, but we&#39;ll leave it there for verbosity.</p>
</blockquote>

<p>This will generate the following <code>filemap.gen.txt</code> for mercurial to use:</p>
<div class="highlight"><pre><code class="language-" data-lang="">include ".hgignore"
include "sln/MyProject.Core"
include "src/MyProject.Core.Api"
include "src/MyProject.Core.Model"
include "src/MyProject.Core.Utils"
include "src/MyProject.Core.Api/App_Data"
include "src/MyProject.Core.Api/App_Start"
include "src/MyProject.Core.Api/Controllers"
include "src/MyProject.Core.Api/Models"
include "src/MyProject.Core.Api/Properties"
include "src/MyProject.Core.Api/Service References"
include "src/MyProject.Core.Api/Service References/Application Insights"
include "src/MyProject.Core.Model/Properties"
include "src/MyProject.Core.Utils/Properties"
remove top-secret.txt
</code></pre></div>
<blockquote>
<p>Some of these entries are in fact obsolete. Once we include a directory, there is no need to include all it&#39;s subdirectories. But since the file is autogenerated, this is not a worry. </p>
</blockquote>

<p>For <code>repo-b</code>, I will go minimalist and use <code>sln:</code> prefix:</p>
<div class="highlight"><pre><code class="language-" data-lang="">include .hgignore
include sln:sln/MyProject.Desktop/MyProject.Desktop.sln
exclude top-secret.txt
</code></pre></div>
<h1 id="conversion-process">Conversion Process</h1>

<p>We will use <code>hg-convert.ps1</code> script to do the conversion. Sample usage:</p>
<div class="highlight"><pre><code class="language-" data-lang="">PS&gt; .\hg-convert path/to/source/convert-me path/to/target/repo-a -startrev 123
</code></pre></div>
<p>This script takes care of configuring and calling <code>hg convert</code>. It will:</p>

<ol>
<li>Take <code>filemap.txt</code> (if it exists), generate <code>filemap.gen.txt</code> and pass it to <code>convert</code></li>
<li>Take <code>branchmap.txt</code> (if it exists), generate <code>branchmap.gen.txt</code> and pass it to <code>convert</code> (more of branchmap later)</li>
<li>Check if the target repository already exists (use <code>-force</code> to force overwrite)</li>
<li>Convert the repository at <code>path/to/source/convert-me</code>, starting at revision <code>123</code> and save it at <code>path/to/target/repo-a</code> </li>
</ol>

<p><code>startrev</code> specifies the revision at which the conversion process should start (and convert it and all of its descendants). If you specify <code>0</code> (default), it will convert whole repository (which may take a considerable time if the repo is big). For testing purpose, I recommend starting with the latest revision. This way, only this one revision will be converted and you can check, if you have included everything you need in the filemap. My process is as follows (this should will save you some time and frustration):</p>

<ol>
<li>Setup filemap </li>
<li><p>Convert only the newest revision, using <code>startrev</code> parameter, i.e:</p>
<div class="highlight"><pre><code class="language-" data-lang="">PS&gt; .\hg-convert ../convert-me ../repo-a -startrev 55
</code></pre></div></li>
<li><p>Check the converted repository - try to build everything</p></li>
<li><p>Copy missing files from old repo to the new repo and add them to filemap, until the new repo builds properly</p></li>
<li><p>Repeat from 2. until I get it rigth</p></li>
<li><p>Start full conversion from revision 0</p>
<div class="highlight"><pre><code class="language-" data-lang="">PS&gt; .\hg-convert ../convert-me ../repo-a -startrev 0
</code></pre></div></li>
</ol>

<p>If everything goes rigth, we got now two separate repositories, <code>repo-a</code> and <code>repo-b</code>. Notify other developers of the change, so no one tries to push to the old repo (renaming or removing it might also be a good way to prevent this). </p>

<p>But wait, there are also some other scenarios whe should cover.</p>

<h3 id="automated-branchmap">Automated branchmap</h3>

<p>Branchmap defines the mapping between branch names in old repo and new repo. <code>branchmap.txt</code> support the following line format:</p>
<div class="highlight"><pre><code class="language-" data-lang=""># this is th basic mercurial stuff:
original_branch_name new_branch_name

# this is extended format:
r:release/.* release
r:!release default
* default
</code></pre></div>
<p>Similar to filemap, <code>r:</code> and <code>r:!</code> denotes regex to match/notmatch. A single <code>*</code> means - you guessed it - &quot;everything&quot;.</p>

<p>For example, my <code>branchmap.txt</code> could look like this:</p>
<div class="highlight"><pre><code class="language-" data-lang="">* default
r:release/.* release
dev dev
</code></pre></div>
<p>All branches that match <code>release/*</code> pattern will be renamed to <code>release</code>. Branch <code>dev</code> will remain <code>dev</code>. Everything else will be renamed to <code>default</code>. </p>

<blockquote>
<p>Note that the order matters here. If a branch matches multiple patterns, the last one will always win. So, start with the most generic one. If you write <code>* default</code> at the end of file, everything before it will be  effectively ignored. You may want to inspect <code>branchmap.gen.txt</code> to see, if everything looks like you wanted. </p>
</blockquote>

<h3 id="appending-revisions-to-existing-repo">Appending revisions to existing repo</h3>

<p>The last thing I want to mention is appending parts of history onto one another. Let&#39;s go back to our <code>convert-me</code> repo. The news of switching to new repositories hasn&#39;t reach one developer, who just pushed some critical changes in <code>MyProject.Core.Model</code> and <code>MyProject.Desktop.WinForms</code> in <code>convert-me</code> repo (instead of <code>repo-a</code> and <code>repo-b</code> respectively) - lets call them &quot;offending changes&quot;. How to transfer these changes to new repos without breaking anything? Run <code>convert</code> again? But this will recreate these repositories, effectively breaking them for everyone who has them checked out.</p>

<p><code>convert</code> gives us a way to append parts of converted history into an existing repo. And this is exactly what we need in this case. We will:</p>

<ol>
<li>specify offending changes (starting from the first revision that hasn&#39;t been converted before)</li>
<li>Check offending changes parent and find corresponding commits in <code>repo-a</code> and <code>repo-b</code></li>
<li>Convert offending changes and append them onto these corresponding parent commits. We will use the same filemaps and branchmaps to filter only required files.</li>
</ol>

<p>Now, that&#39;s it. Hope you find this helpful and if you have any problems with the scripts - please drop me a line! </p>

<h1 id="resources">Resources</h1>

<ul>
<li><a href="https://www.mercurial-scm.org/wiki/ConvertExtension">https://www.mercurial-scm.org/wiki/ConvertExtension</a></li>
<li><a href="http://hgtip.com/tips/advanced/2009-11-16-using-convert-to-decompose-your-repository/">http://hgtip.com/tips/advanced/2009-11-16-using-convert-to-decompose-your-repository/</a></li>
<li><a href="https://gist.github.com/qbikez/e900456032833fb2baaaee87e19a8ccd">https://gist.github.com/qbikez/e900456032833fb2baaaee87e19a8ccd</a></li>
</ul>

	  ]]></description>
	</item>

	<item>
	  <title>Powershell on Linux</title>
	  <link>//powershell-on-linux</link>
	  <author>qbik</author>
	  <pubDate>2016-08-24T00:00:00+02:00</pubDate>
	  <guid>//powershell-on-linux</guid>
	  <description><![CDATA[
	     <p>A few days ago <a href="https://azure.microsoft.com/en-us/blog/powershell-is-open-sourced-and-is-available-on-linux/">Microsoft has announced Powershell on Linux</a>. You can get it from <a href="https://github.com/powershell/powershell">Powershell&#39;s Github</a>. This is a big announcement and perfectly complies with “Microsoft loves Linux” philosophy.</p>

<p>The installation (here, for Ubuntu 14.04) is pretty straightforward:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">$ </span>wget https://github.com/PowerShell/PowerShell/releases/download/v6.0.0-alpha.9/powershell_6.0.0-alpha.9-1ubuntu1.14.04.1_amd64.deb
<span class="gp">$ </span>sudo apt-get install libunwind8 libicu52
<span class="gp">$ </span>sudo dpkg -i powershell_6.0.0-alpha.9-1ubuntu1.14.04.1_amd64.deb</code></pre></figure>

<p>So now, I can do this:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">&gt; </span>c:<span class="se">\w</span>indows<span class="se">\s</span>ystem32<span class="se">\b</span>ash
<span class="gp">$ </span>whereis powershell
powershell: /usr/bin/powershell
<span class="gp">$ </span>powershell
<span class="gp">PS&gt; </span>write-host <span class="s2">"hello world!"</span>
hello world!</code></pre></figure>

<p>Yay, look at that: Powershell on Bash on Windows :)</p>

<p>Of course, the important thing here is that the same works on a <em>real</em> Linux.</p>

<h1 id="what-works">What works?</h1>

<blockquote>
<p>Note: This is PowerShell <code>v6.0.0-alpha.9</code>, so you can expect &quot;Alpha-quality&quot; and &quot;things won&#39;t work&quot;.</p>
</blockquote>

<p>Let&#39;s take a look at available preinstalled modules:</p>

<figure class="highlight"><pre><code class="language-powershell" data-lang="powershell"><span class="nb">PS</span>&gt; Get-Module -ListAvailable

    Directory: /opt/microsoft/powershell/6.0.0-alpha.9/Modules


ModuleType Version    Name                                ExportedCommands
---------- -------    ----                                ----------------
Manifest   1.0.1.0    Microsoft.PowerShell.Archive        <span class="o">{</span>Compress-Archive, Expand-Archive<span class="o">}</span>
Manifest   3.0.0.0    Microsoft.PowerShell.Host           <span class="o">{</span><span class="nb">Start-Transcript</span>, <span class="nb">Stop-Transcript</span><span class="o">}</span>
Manifest   3.1.0.0    Microsoft.PowerShell.Management     <span class="o">{</span><span class="nb">Add-Content</span>, <span class="nb">Clear-Content</span>, <span class="nb">Clear</span>-ItemProperty, Join-Path...<span class="o">}</span>
Manifest   3.0.0.0    Microsoft.PowerShell.Security       <span class="o">{</span><span class="nb">Get-Credential</span>, <span class="nb">Get-ExecutionPolicy</span>, <span class="nb">Set-ExecutionPolicy</span>, ConvertFrom-SecureString...<span class="o">}</span>
Manifest   3.1.0.0    Microsoft.PowerShell.Utility        <span class="o">{</span><span class="nb">Format-List</span>, <span class="nb">Format-Custom</span>, <span class="nb">Format-Table</span>, Format-Wide...<span class="o">}</span>
Binary     1.0.0.1    PackageManagement                   <span class="o">{</span>Find-Package, Get-Package, Get-PackageProvider, Get-PackageSource...<span class="o">}</span>
Script     3.3.9      Pester                              <span class="o">{</span>Describe, Context, It, Should...<span class="o">}</span>
Script     1.0.0.1    PowerShellGet                       <span class="o">{</span>Install-Module, Find-Module, Save-Module, Update-Module...<span class="o">}</span>
Script     0.0        PSDesiredStateConfiguration         <span class="o">{</span>IsHiddenResource, StrongConnect, <span class="nb">Write</span>-MetaConfigFile, Get-InnerMostErrorRecord...<span class="o">}</span>
Script     1.2        PSReadLine                          <span class="o">{</span>Get-PSReadlineKeyHandler, <span class="nb">Set</span>-PSReadlineKeyHandler, Remove-PSReadlineKeyHandler, Get-PSReadlineO...</code></pre></figure>

<p>Note that PowerShellGet is available, so you should be able to install modules from <a href="http://powershellgallery.com">Powershell Gallery</a>:</p>

<figure class="highlight"><pre><code class="language-powershell" data-lang="powershell"><span class="nb">PS</span>&gt; Install-Module PathUtils</code></pre></figure>

<p>But this seem to be broken for now:</p>

<figure class="highlight"><pre><code class="language-powershell" data-lang="powershell">    PackageManagement<span class="se">\I</span>nstall-Package : Could not <span class="nb">compare</span> <span class="s2">"6.0.0-alpha"</span> to <span class="s2">"5.0"</span>. Error:
    <span class="s2">"Cannot convert value "</span>5.0<span class="s2">" to type "</span>System.Management.Automation.SemanticVersion<span class="s2">". Error:
    "</span>Cannot <span class="k">process </span>argument because the value of argument <span class="s2">"version"</span> is not valid. Change the value of the <span class="s2">"version"</span> argument and run the operation again.</code></pre></figure>

<p>There already is a <a href="https://github.com/bmanikm/PowerShell/commit/97eb76cf9841faf1754028842ee5a1eb11516538">fix for this particular problem</a>. If you want to use that patch:</p>

<figure class="highlight"><pre><code class="language-powershell" data-lang="powershell"><span class="gp">$ </span>sudo <span class="nb">cp</span> /opt/microsoft/powershell/6.0.0-alpha.9/Modules/PowerShellGet/PSModule.psm1 /opt/microsoft/powershell/6.0.0-alpha.9/Modules/PowerShellGet/PSModule.psm1.bak
<span class="gp">$ </span>sudo <span class="nb">wget </span>https://raw.githubusercontent.com/bmanikm/PowerShell/97eb76cf9841faf1754028842ee5a1eb11516538/src/Modules/Shared/PowerShellGet/PSModule.psm1 -O /opt/microsoft/powershell/6.0.0-alpha.9/Modules/PowerShellGet/PSModule.psm1</code></pre></figure>

<p>And voila, <code>Install-Module</code> works.</p>

<blockquote>
<p>Watch out: Unix is case-sensitive! Although Powershell is not, you have to use the right casing of module names. So <code>Import-Module PathUtils</code> will work, whereas <code>Import-Module pathutils</code> will fail. Also, the name of the psd1 file has to match exactly the name of the module (this is important for module maintainers).</p>
</blockquote>

<h1 id="open-source-everything">Open source everything</h1>

<p>As excited as I am with running PowerShell scripts on Linux, I think that the most important thing here is the open sourcing of PowerShell. If Microsoft didn&#39;t prepare a version that runs on Linux, some other geek would probably do it (sooner or later).
But the fact that I can now look into PS source code and see, how they do things, then tinker around and send a pull request is really amazing. I&#39;ve been using Asp.Net Core for some time now and the possibility to just look at the source code proven invaluable a cuple of times.</p>

<blockquote>
<p>It&#39;s worth mentioning that there already exists an open source effort to reimplement Powershell: <a href="https://github.com/Pash-Project/Pash">Pash</a>. I wonder what will become of it now.</p>
</blockquote>

<h1 id="possiblities">Possiblities</h1>

<p>Taking aside the excitement of &quot;because I can&quot;, what are real benefits of using PowerShell on Linux, when you have Bash available at your disposal? </p>

<h2 id="build-scripts">Build scripts</h2>

<p>Up until now, cross platform .Net projects, like Dotnet CLI itself, used separate build scripts for Linux and Windows. Now, it will be possible to write one PowerShell script to rule them all. I personally have tons of build/deploy/other DevOps scripts written in PowerShell (and DSC). I would rather gladly test them on Linux and work around the rough edges than rewrite all that stuff in Bash (and maintain two separate versions). </p>

<p>If you think of dockerizing your services, the possibility to use the same scripts on Linux and Windows should make the transition much smoother.</p>

<h2 id="managing-the-cloud">Managing the cloud</h2>

<p>If you are managing multiple Linux and Windows machines, you will be able to use the same shell and scripts for all of them. Also, as MS announcement says:</p>

<blockquote>
<p>We will be extending the PowerShell Remoting Protocol (MS-PSRP) to use OpenSSH as a native transport. Users will have the option to use SSH or WINRM as a transport.</p>
</blockquote>

<p>So, you will be able to do something like:</p>

<figure class="highlight"><pre><code class="language-powershell" data-lang="powershell"><span class="nb">PS</span>&gt; Invoke-Command -ComputerName MyLinux <span class="o">{</span> wtite-host <span class="s2">"this is me executing remotely"</span> <span class="o">}</span></code></pre></figure>

<p>And that will work over SSH, without the struggle of setting up WINRM.</p>

<h1 id="whats-next">What&#39;s next</h1>

<p>As of today, there are <a href="https://github.com/powershell/powershell/issues">322 issues</a>, so Powershell 6 has some way to go before it&#39;s &quot;production ready&quot;. But I&#39;m not waiting until then - I&#39;m starting to make my scripts and modules &quot;cross-platform&quot; with PowerShell 6 right now.</p>

	  ]]></description>
	</item>

	<item>
	  <title>Adding Web Deploy permissions using PowerShell</title>
	  <link>//iis-web-deploy-permissions</link>
	  <author>qbik</author>
	  <pubDate>2016-08-07T00:00:00+02:00</pubDate>
	  <guid>//iis-web-deploy-permissions</guid>
	  <description><![CDATA[
	     <p>Web Deploy is a great way to publish websites if you use Windows + IIS hosting, especially inside company&#39;s infrastructure. </p>

<p>Why do I like it:</p>

<ul>
<li>It can be used from Visual Studio as well as from commandline - this means developers can publish right from VS, without any additional tools, but also script and commandline freaks like me can automate it</li>
<li>It only syncs modified files - if you have low bandwith, deploy often or have large sites - it beats other methods that require full package to be deployed every time</li>
<li>Active Directory can be used for authentication</li>
</ul>

<h1 id="allowing-a-user-to-publish-with-web-deploy">Allowing a user to publish with Web Deploy</h1>

<p>The goal is to allow non-administrator user to publish IIS website using Web Deploy. </p>

<p>There are two parts here:</p>

<ol>
<li>Add IIS Manager permissions</li>
<li>Add File System permissions</li>
</ol>

<p>If you like clicking through it, see <a href="https://www.iis.net/learn/install/installing-publishing-technologies/installing-and-configuring-web-deploy-on-iis-80-or-later">Installing and Configuring Web Deploy on IIS 8.0 or Later</a>. Remember that you should also add appropriate permissions to site&#39;s physical folder or else the user won&#39;t be able to publish any files. </p>

<p>If you want to do it from commandline, here&#39;s a snippet for <a href="https://blogs.iis.net/carlosag/adding-iis-manager-users-and-permissions-using-powershell">setting IIS Manager permissions</a>:</p>
<div class="highlight"><pre><code class="language-" data-lang="">[System.Reflection.Assembly]::LoadWithPartialName("Microsoft.Web.Management") 
[Microsoft.Web.Management.Server.ManagementAuthorization]::Grant($username, "$site", $false) 
</code></pre></div>
<p>Then, use <code>Set-Acl</code> to set physical path permissions. Here&#39;s a full script:</p>
<div class="highlight"><pre><code class="language-" data-lang="">&lt;#
.SYNOPSIS

adds ACL rules to specific path. it's a helper wrapper for Set-ACL from Microsoft.PowerShell.Security   

#&gt;

function set-acl2(
[Parameter(Mandatory=$true)] $path, 
[Parameter(Mandatory=$true)] [System.Security.AccessControl.FileSystemRights] $rights, 
[Parameter(Mandatory=$true)] $user,
[System.Security.AccessControl.InheritanceFlags]  $InheritanceFlag = [System.Security.AccessControl.InheritanceFlags]::None,
 [System.Security.AccessControl.PropagationFlags] $PropagationFlag = [System.Security.AccessControl.PropagationFlags]::None
) {
    $colRights = $rights

    $PropagationFlag = [System.Security.AccessControl.PropagationFlags]::None 

    $objType =[System.Security.AccessControl.AccessControlType]::Allow 

    $objUser = New-Object System.Security.Principal.NTAccount($user) 

    $objACE = New-Object System.Security.AccessControl.FileSystemAccessRule ($objUser, $colRights, $InheritanceFlag, $PropagationFlag, $objType) 

    $objACL = (Get-Item $path).GetAccessControl('Access')#(Get-ACL $path).GetAccessControl('Access')
    $objACL.AddAccessRule($objACE) 

    Set-ACL -Path $path -AclObject $objACL
}

&lt;#

.SYNOPSIS 
Allows the specified user to publish website through webdeploy

#&gt;    
function allow-iiswebdeploy {
param(
    [Parameter(Mandatory=$true)] $username,
    [Parameter(Mandatory=$true)] $site,
    [Switch][bool] $isgroup
)

    ipmo webadministration


    $iissite = get-item "iis:\sites\$site" -ErrorAction Stop

    if ($iissite -eq $null) { throw "site '$site' not found" }

    # add  IIS Manager Users and Permissions
    # from: https://blogs.iis.net/carlosag/adding-iis-manager-users-and-permissions-using-powershell

    [System.Reflection.Assembly]::LoadWithPartialName("Microsoft.Web.Management") 
    [Microsoft.Web.Management.Server.ManagementAuthorization]::Grant($username, "$site", $isgroup) 

    # grant file system permissions!

    $dir = $iissite.physicalPath

    set-acl2 -path $dir -rights CreateFiles,Delete,Modify,CreateDirectories,ReadAndExecute -user $username -InheritanceFlag ObjectInherit,ContainerInherit 
}
</code></pre></div>
<p>Just call:</p>
<div class="highlight"><pre><code class="language-" data-lang="">PS&gt; allow-iiswebdeploy -username "MYDOMAIN\user" -site "Default Web Site"
</code></pre></div>
<p>And that&#39;s it! Note that site&#39;s physical path is obtained directly from IIS.</p>

<h1 id="resources">Resources</h1>

<p><a href="https://www.iis.net/learn/publish/using-web-deploy/web-deploy-powershell-cmdlets">https://www.iis.net/learn/publish/using-web-deploy/web-deploy-powershell-cmdlets</a></p>

	  ]]></description>
	</item>


</channel>
</rss>
